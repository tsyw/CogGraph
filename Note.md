## Link
[Cognitive Graph for Multi-Hop Reading Comprehension at Scale](https://arxiv.org/pdf/1905.05460.pdf)

[GitHub](https://github.com/THUDM/CogQA)

本文试图模仿人类对文本的阅读理解来解决认知图谱的问题，提出了CogQA框架。人类的阅读理解（Dual process theory）可以分为两个部分：

1. 无意识部分

2. 有意识部分

其中在第一个部分中，通过无意识地抽取关键词，根据关键词在脑中检索信息。在第二个部分中，人们有意识地采用上下文来进行逻辑推理。

在采用机器进行这种阅读理解时，需要解决三个问题：

1. 推理，前人的工作已经对单一文本中的推理得到了很好的结果，但是对于多个文本联合起来的推理没有很好地解决。

2. 可解释性，作为人类推理的一部分，逻辑链条很重要，因此机器想要解决这个问题，就需要解决这个逻辑链条的问题。

3. 可扩展性，对于巨大的知+识库中，如何在巨量的数据中推理也是一个需要解决的问题。

本文的CogQA框架基于BERT和GNN，对多跳阅读理解给出了可解释，可推理的结果，这个结果对之前的工作取得了巨大的提升。

## CogQA 框架

这个框架包括两个系统，分别采用BERT和GNN实现，第一个系统和人类的情况类似，维护一个不断扩展的图，图中每个节点是词，这些可能是候选回答或者新跳转词，收集一些关于这些节点和图的证据（系统2），这些证据可能由一些句子组成，这个系统的输出是关于问题，节点以及证据的语义信息，它同时也会不断扩展图，具体地，不断获取关于节点的文本，将新节点和新边加入图中。第二个系统，利用深度学习的算法，根据语义信息，来计算这个图中的各个节点的隐表示，同时为新节点准备新的证据。针对上面的后两个问题，这个系统作出了一定的解答：

1. 可解释性：对于系统一的输入，即网络的节点，每次迭代，收集关于这个网络的证据信息，这在一定程度上，和人类的认识途径类似，同时对于新引入的边集合，这些节点也会重复访问。

2. 可扩展性：传统方案是基于检索/提取的，因此很可能跳转的文本和问题的语义关系不强，从而大量的信息是无效的，在本框架中，对关键节点的扩展，从而一步一步地提高信息量，因此本身就是可扩展的。

## 实验

实验：Redis6.0.5, torch1.5.1

代码主函数采用’bert-base-uncased‘作为预训练的模型并转换问题为词向量。

系统1的输入：[CLS] Question [SEP] clues[x, G] [SEP] Para[x]，对于回答节点，最后一项可以不存在，1-hop节点，第二项也可能不存在，系统1的输出是LxH维度的矩阵，其中L是输入的长度，H是隐表示的长度，包括语义向量，下一跳的节点和回答节点范围。

作为问题的预测，最终，采用一个两层的神经网络，其输入是所有回答节点的隐表示，输出为具体的答案。

代码的训练分为两个任务，其中任务1用于节点扩展，任务2用于回答节点的预测。

任务1：

新的扩展数据来源于基于莱文斯坦距离的模糊匹配。匹配出来新的节点范围后，对回答节点和下一跳节点的起点和终点采用交叉熵损失进行训练。

实验非常耗时。


